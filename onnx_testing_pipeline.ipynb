{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "from numpy import float32, float64, int32, int64, ndarray\n",
    "from numpy.typing import NDArray\n",
    "from PIL import ImageOps\n",
    "import PIL.Image\n",
    "from PIL.Image import Image, Resampling\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Protocol, Sequence, runtime_checkable, List, cast\n",
    "from onnxruntime import InferenceSession\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PNodeArg(Protocol):\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Any:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def type(self) -> str:\n",
    "        ...\n",
    "\n",
    "\n",
    "class PSparseTensor(Protocol):\n",
    "    values: ndarray\n",
    "    indices: ndarray\n",
    "    shape: tuple[int]\n",
    "\n",
    "    @property\n",
    "    def dtype(self) -> Any:\n",
    "        ...\n",
    "\n",
    "class PInferenceSession(Protocol):\n",
    "    def run(\n",
    "        self, output_names, input_feed: dict[str, Any], run_options=None\n",
    "    ) -> list[ndarray] | list[list] | list[dict] | list[PSparseTensor]:\n",
    "        ...\n",
    "\n",
    "    def get_inputs(self) -> list[PNodeArg]:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageTensor:\n",
    "    original_size: tuple[int, int]\n",
    "    scale_size: tuple[int, int]\n",
    "    data: ndarray\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Label:\n",
    "    x: int\n",
    "    y: int\n",
    "    width: int\n",
    "    height: int\n",
    "    classifier: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LabelImage:\n",
    "    source: Optional[str]\n",
    "    # path: str\n",
    "    width: int\n",
    "    height: int\n",
    "    labels: Sequence[Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box: NDArray[int32], boxes: NDArray[int32]) -> NDArray[float64]:\n",
    "    # Compute xmin, ymin, xmax, ymax for both boxes\n",
    "    xmin = np.minimum(box[0], boxes[:, 0])\n",
    "    ymin = np.minimum(box[1], boxes[:, 1])\n",
    "    xmax = np.maximum(box[0] + box[2], boxes[:, 0] + boxes[:, 2])\n",
    "    ymax = np.maximum(box[1] + box[3], boxes[:, 1] + boxes[:, 3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Compute union area\n",
    "    box_area = box[2] * box[3]\n",
    "    boxes_area = boxes[:, 2] * boxes[:, 3]\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(\n",
    "    boxes: NDArray[int32], scores: NDArray[float32], iou_threshold: float\n",
    ") -> list[int64]:\n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the last box\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        # print(keep_indices.shape, sorted_indices.shape)\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(img: Image, model: PInferenceSession) -> ImageTensor:\n",
    "    _, _, width, height = model.get_inputs()[0].shape\n",
    "\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    original_size = img.size\n",
    "\n",
    "    img = ImageOps.contain(img, (width, height), Resampling.BILINEAR)\n",
    "    scale_size = img.size\n",
    "\n",
    "    img = ImageOps.pad(\n",
    "        img, (width, height), Resampling.BILINEAR, (114, 114, 114), (0, 0)\n",
    "    )\n",
    "    data = np.array(img)\n",
    "\n",
    "    data = data / 255.0\n",
    "    data = data.transpose(2, 0, 1)\n",
    "    tensor = data[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "    return ImageTensor(original_size, scale_size, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PInferenceSession,\n",
    "        names: list[str],\n",
    "        conf_threshold: float = 0.25,\n",
    "        iou_threshold: float = 0.7,\n",
    "    ) -> None:\n",
    "        self.__model = model\n",
    "        self.__names = names\n",
    "        self.__conf_threshold = conf_threshold\n",
    "        self.__iou_threshold = iou_threshold\n",
    "\n",
    "    def predict(self, img: Image | str) -> LabelImage:\n",
    "        if isinstance(img, str):\n",
    "            img = PIL.Image.open(img)\n",
    "\n",
    "        tensor = image_to_tensor(img, self.__model)\n",
    "        results = cast(List[ndarray], self.__model.run(None, {\"images\": tensor.data}))\n",
    "        predictions = np.squeeze(results[0]).T\n",
    "\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        keep = scores > self.__conf_threshold\n",
    "        predictions = predictions[keep, :]\n",
    "        scores = scores[keep]\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        boxes = predictions[:, :4]\n",
    "        boxes[:, 0:2] -= boxes[:, 2:4] / 2\n",
    "        boxes /= np.array(\n",
    "            [*tensor.scale_size, *tensor.scale_size], dtype=np.float32\n",
    "        )\n",
    "        boxes *= np.array([*tensor.original_size, *tensor.original_size])\n",
    "        boxes = boxes.astype(np.int32)\n",
    "\n",
    "        keep = nms(boxes, scores, self.__iou_threshold)\n",
    "        labels = []\n",
    "        for bbox, label in zip(boxes[keep], class_ids[keep]):\n",
    "            labels.append(\n",
    "                Label(\n",
    "                    x=bbox[0].item(),\n",
    "                    y=bbox[1].item(),\n",
    "                    width=bbox[2].item(),\n",
    "                    height=bbox[3].item(),\n",
    "                    classifier=self.__names[label],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        img_width, img_height = img.size\n",
    "        return LabelImage(\n",
    "            source=None,\n",
    "            # path=img.filename,  # type: ignore\n",
    "            width=img_width,\n",
    "            height=img_height,\n",
    "            labels=labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_names_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        objects = file.read().splitlines()\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Label(x=1307, y=763, width=440, height=315, classifier='barcode'), Label(x=1298, y=2365, width=440, height=236, classifier='barcode'), Label(x=1260, y=1332, width=520, height=304, classifier='barcode'), Label(x=1334, y=1912, width=480, height=271, classifier='barcode'), Label(x=1057, y=3286, width=326, height=180, classifier='barcode'), Label(x=553, y=2220, width=92, height=87, classifier='qrcode'), Label(x=1114, y=2893, width=193, height=98, classifier='barcode'), Label(x=798, y=2230, width=94, height=85, classifier='qrcode'), Label(x=687, y=1201, width=108, height=111, classifier='qrcode'), Label(x=803, y=1782, width=100, height=98, classifier='qrcode'), Label(x=535, y=1773, width=100, height=102, classifier='qrcode'), Label(x=667, y=1776, width=106, height=103, classifier='qrcode'), Label(x=673, y=2223, width=97, height=89, classifier='qrcode'), Label(x=544, y=1204, width=111, height=115, classifier='qrcode'), Label(x=855, y=731, width=409, height=115, classifier='barcode'), Label(x=858, y=2882, width=184, height=96, classifier='barcode'), Label(x=1344, y=1192, width=348, height=95, classifier='barcode'), Label(x=934, y=1782, width=107, height=102, classifier='qrcode'), Label(x=919, y=2234, width=99, height=90, classifier='qrcode'), Label(x=1390, y=2914, width=211, height=88, classifier='barcode'), Label(x=401, y=1208, width=107, height=111, classifier='qrcode'), Label(x=1379, y=2264, width=301, height=76, classifier='barcode'), Label(x=828, y=1197, width=115, height=115, classifier='qrcode'), Label(x=490, y=3004, width=95, height=78, classifier='qrcode'), Label(x=861, y=2722, width=131, height=110, classifier='qrcode'), Label(x=612, y=3011, width=100, height=74, classifier='qrcode'), Label(x=370, y=2994, width=93, height=80, classifier='qrcode'), Label(x=1375, y=1802, width=338, height=81, classifier='barcode'), Label(x=1309, y=2779, width=219, height=67, classifier='barcode'), Label(x=180, y=3287, width=330, height=90, classifier='barcode'), Label(x=1116, y=3213, width=273, height=59, classifier='barcode')]\n"
     ]
    }
   ],
   "source": [
    "# Code snippet to load the model and run the inference on a single image\n",
    "\n",
    "def model_load(model , names_path):\n",
    "    classes = read_names_file(names_path)\n",
    "    session = InferenceSession(\n",
    "        model,\n",
    "        providers=[\n",
    "            # \"CUDAExecutionProvider\",\n",
    "            \"CPUExecutionProvider\",\n",
    "        ],\n",
    "    )\n",
    "    predictor = Predictor(session, classes, conf_threshold = 0.3, iou_threshold = 0.4)\n",
    "    return predictor\n",
    "\n",
    "# Input the model path, .names file and the image path for inference\n",
    "model = \"optimized_model.onnx\" \n",
    "names_path = \"obj.names\"\n",
    "img_cv2 = cv2.imread(\"img.jpg\")\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "img = PIL.Image.fromarray(img_rgb)\n",
    "\n",
    "predictor = model_load(model, names_path)\n",
    "results = predictor.predict(img)\n",
    "\n",
    "print(results.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully processed 57 images\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhava\\AppData\\Local\\Temp\\ipykernel_2244\\3363175807.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  iou = intersection_area / union_area\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully processed 197 images\n",
      "\n",
      "Succesfully processed 86 imagestion KYBM and Accessories dir\n",
      "\n",
      "Succesfully processed 30 images KYBM and Accesorries dir\n",
      "\n",
      "Succesfully processed 61 imageseadphone,Soundbar,Speaker dir\n",
      "\n",
      "Sucessfully processed Large and small Appliance dir\r"
     ]
    }
   ],
   "source": [
    "# Code snippet for testing the onnx model\n",
    "def onnx_testing(predictor, annotated_label_dir, image_base_dir):\n",
    "    image_dir_list = os.listdir(image_base_dir)\n",
    "    result_list = []\n",
    "    for base_dir in image_dir_list:\n",
    "        \n",
    "        if base_dir == '.DS_Store': continue\n",
    "    \n",
    "        image_dir = image_base_dir + base_dir + '/'\n",
    "        image_list = os.listdir(image_dir)\n",
    "    \n",
    "        for count, images in enumerate(image_list):\n",
    "            result_dict = {}\n",
    "            result_dict[\"Image Name\"] = images\n",
    "        \n",
    "            barCode = 0\n",
    "            qrCode = 0\n",
    "            predBarCode = 0\n",
    "            predQrCode = 0\n",
    "            ext = images.split(\".\")[-1]\n",
    "            if ext != 'jpg': continue\n",
    "            image_path = image_dir + images\n",
    "        \n",
    "            if os.path.exists(image_path):\n",
    "                image_cv2 = cv2.imread(image_path)\n",
    "                image_rgb = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)\n",
    "                image = PIL.Image.fromarray(image_rgb)\n",
    "                results = predictor.predict(image)\n",
    "                classes = []\n",
    "                boxes = []\n",
    "                for i in range(0 , len(results.labels)):\n",
    "                    classes.append(results.labels[i].classifier)\n",
    "                    x = results.labels[i].x\n",
    "                    y = results.labels[i].y\n",
    "                    width = results.labels[i].width\n",
    "                    height = results.labels[i].height\n",
    "                    box_coord = (x , y , width , height) \n",
    "                    boxes.append(box_coord)\n",
    "        \n",
    "                for items in classes:\n",
    "                    if items == \"qrcode\":\n",
    "                        predQrCode+=1\n",
    "                    if items == \"barcode\":\n",
    "                        predBarCode+=1\n",
    "            \n",
    "                print(f'Succesfully processed {count+1} images', end='\\r')\n",
    "\n",
    "                annot_label = images.replace(\".jpg\", \".txt\")\n",
    "                annot_label_path = annotated_label_dir + annot_label\n",
    "\n",
    "\n",
    "                if os.path.exists(annot_label_path):\n",
    "                    with open(annot_label_path, 'r') as file:\n",
    "                        data_list = file.readlines()\n",
    "                    for data in data_list:\n",
    "                        pred_class, cx, cy, w, h = data.split(\" \")\n",
    "                        if pred_class == '1':\n",
    "                            qrCode+=1\n",
    "                        if pred_class == '0':\n",
    "                            barCode+=1\n",
    "                    result_dict[\"Actual QR\"] = qrCode\n",
    "                    result_dict[\"Predicted QR\"] = predQrCode\n",
    "                    result_dict[\"Actual Barcode\"] = barCode\n",
    "                    result_dict[\"Predicted Barcode\"] = predBarCode\n",
    "\n",
    "                if not os.path.exists(annot_label_path):\n",
    "                    result_dict[\"Actual QR\"] = 'NA'\n",
    "                    result_dict[\"Predicted QR\"] = predQrCode\n",
    "                    result_dict[\"Actual Barcode\"] = 'NA'\n",
    "                    result_dict[\"Predicted Barcode\"] = predBarCode\n",
    "                result_dict[\"Bounding Boxes\"] = boxes\n",
    "            result_list.append(result_dict)\n",
    "        print('\\n')\n",
    "        print(f'Sucessfully processed {base_dir} dir', end='\\r')\n",
    "        \n",
    "    return result_list\n",
    "\n",
    "# Input the annotated label directory and image folder path\n",
    "annot_label_dir = 'labels/labels/'\n",
    "img_base_dir = 'Chroma_Image_Analytics_2909/Chroma_Image_Analytics_2909/'\n",
    "\n",
    "result_list = onnx_testing(predictor, annot_label_dir, img_base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Actual QR</th>\n",
       "      <th>Predicted QR</th>\n",
       "      <th>Actual Barcode</th>\n",
       "      <th>Predicted Barcode</th>\n",
       "      <th>Bounding Boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG20230105115725.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(1012, 3401, 366, 116)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG20230105120217.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[(1847, 2619, 411, 224), (1878, 2225, 416, 205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG20230105120254.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[(1813, 3573, 645, 330), (349, 2744, 575, 559)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG20230105120349.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[(992, 1003, 359, 362), (1016, 2026, 412, 197)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG20230105120349_01.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[(1723, 2732, 356, 358), (1572, 1397, 405, 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>IMG20230105141539.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(1288, 683, 178, 193)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>IMG20230105141544.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(1363, 1821, 144, 142)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>IMG20230105141549.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(1489, 698, 164, 171)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Scan from 2023-01-05 03_51_53 PM.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(0, 794, 261, 216), (521, 1314, 389, 83)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Scan from 2023-01-05 03_53_14 PM.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(476, 1132, 172, 351), (441, 515, 137, 521)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Image Name  Actual QR  Predicted QR   \n",
       "0                   IMG20230105115725.jpg          0             0  \\\n",
       "1                   IMG20230105120217.jpg          0             0   \n",
       "2                   IMG20230105120254.jpg          1             0   \n",
       "3                   IMG20230105120349.jpg          1             1   \n",
       "4                IMG20230105120349_01.jpg          1             1   \n",
       "..                                    ...        ...           ...   \n",
       "227                 IMG20230105141539.jpg          1             1   \n",
       "228                 IMG20230105141544.jpg          1             1   \n",
       "229                 IMG20230105141549.jpg          1             1   \n",
       "230  Scan from 2023-01-05 03_51_53 PM.jpg          0             0   \n",
       "231  Scan from 2023-01-05 03_53_14 PM.jpg          0             0   \n",
       "\n",
       "     Actual Barcode  Predicted Barcode   \n",
       "0                 1                  1  \\\n",
       "1                 6                  6   \n",
       "2                 1                  2   \n",
       "3                 4                  4   \n",
       "4                 4                  4   \n",
       "..              ...                ...   \n",
       "227               0                  0   \n",
       "228               0                  0   \n",
       "229               0                  0   \n",
       "230               2                  2   \n",
       "231               2                  2   \n",
       "\n",
       "                                        Bounding Boxes  \n",
       "0                             [(1012, 3401, 366, 116)]  \n",
       "1    [(1847, 2619, 411, 224), (1878, 2225, 416, 205...  \n",
       "2      [(1813, 3573, 645, 330), (349, 2744, 575, 559)]  \n",
       "3    [(992, 1003, 359, 362), (1016, 2026, 412, 197)...  \n",
       "4    [(1723, 2732, 356, 358), (1572, 1397, 405, 195...  \n",
       "..                                                 ...  \n",
       "227                            [(1288, 683, 178, 193)]  \n",
       "228                           [(1363, 1821, 144, 142)]  \n",
       "229                            [(1489, 698, 164, 171)]  \n",
       "230         [(0, 794, 261, 216), (521, 1314, 389, 83)]  \n",
       "231      [(476, 1132, 172, 351), (441, 515, 137, 521)]  \n",
       "\n",
       "[232 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the out directory\n",
    "out_dir = 'test_results/'\n",
    "excel_path = out_dir + 'model_metrics.xlsx'\n",
    "df.to_excel(excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akshayakumarmaharana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
